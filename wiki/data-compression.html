<!DOCTYPE html>
	<html lang="en">
		<head>
		<meta charset="utf-8">
		<meta name="viewport" content="width=device-width, initial-scale=1.0">
		<link rel="icon" type="image/svg+xml" href="data:image/svg+xml,<svg xmlns=%22http://www.w3.org/2000/svg%22 width=%22256%22 height=%22256%22 viewBox=%220 0 100 100%22><rect width=%22100%22 height=%22100%22 rx=%2220%22 fill=%22%23d8eaeb%22></rect><text x=%2250%%22 y=%2250%%22 dominant-baseline=%22central%22 text-anchor=%22middle%22 font-size=%2293%22>üå≥</text></svg>" />
            <title>Introduction to Data Compression</title>
			<link rel="canonical" href="https://strikingloo.github.io/wiki/data-compression">
			  <meta name="description" content="Notes on 'Introduction to Data Compression' by Guy E. Blelloch, Computer Science Department, Carnegie Mellon University.">
  			<meta property="og:site_name" content="Introduction to Data Compression">

        	
        	<link rel="stylesheet" type="text/css" href="/css/post-min.css">
        	

			<script async src="https://www.googletagmanager.com/gtag/js?id=UA-52642322-5"></script>

			<script>
			  window.dataLayer = window.dataLayer || [];
			  function gtag(){dataLayer.push(arguments);}
			  gtag('js', new Date());

			  gtag('config', 'UA-52642322-5');
			</script>
			
			  <meta property="og:description" content="Notes on 'Introduction to Data Compression' by Guy E. Blelloch, Computer Science Department, Carnegie Mellon University.">
			
	  		<meta property="og:locale" content="en_US">
	  		
			  <meta property="og:title" content="Introduction to Data Compression">
			  <meta property="og:type" content="article">
		  	  <meta property="article:published_time" content="2022-08-07T00:00:00+00:00">
		      <meta property="article:author" content="/">
		  	
		  	
  				<meta property="og:url" content="https://strikingloo.github.io/wiki/data-compression">
  			
  			<meta content="index,follow" name="robots"><!-- All Search Engines -->
  			<meta content="index,follow" name="googlebot"><!-- Google Specific -->
  			<meta name="robots" content="max-image-preview:large">

		</head>
		<body>
			<div class="head-banner">
			<p>Strikingloo</p>
			<nav>
	    		<ul>
	        		<li><a href="/">Home</a></li>
		        	<li><a href="/about/">About</a></li>
	        		<li><a href="/wiki/">Wiki</a></li>
	        		<li><a href="/blog/">Blog </a></li>
	    		</ul>
			</nav>
			<div style="clear: both;"></div>
		    </div>

			<div class="container">
			
			<h1>Introduction to Data Compression</h1>
<p class="meta">07 Aug 2022 - importance: 7 </p>



<p class="abstract" style="background-color: #E2DCC8;
border:2px solid;
font-style:italic;
margin:5%;
text-align: center;
padding:2%;"> Notes on 'Introduction to Data Compression' by Guy E. Blelloch, Computer Science Department, Carnegie Mellon University. Including how Huffman Encoding, Arithmetic Coding, PPM, LZ, ZIP, JPEG and MPEG work.</p>


<div class="post">
  <p><a href="https://www.cs.cmu.edu/~guyb/realworld/compression.pdf">‚ÄòIntroduction to Data Compression‚Äô by Guy E. Blelloch.</a></p>

<p>Compression algorithms map a message (for example, a file) to a reduced version. They are composed of a pair of encoding and decoding procedures, such that a message is compressed by the former and recovered by the latter. The process can be lossless, where the recovered message is exactly the same as before, or lossy, where a part of the message (hopefully one deemed less important) may be lost in the process.</p>

<p>Commonly, lossless compression is used on text, and lossy is saved for images, audio and other media forms where exact recovery is not as necessary.</p>

<p>‚ÄúBecause one can‚Äôt hope to compress everything [since an isomorphism ould necessarily require the same amount of bits in the end], all compression algorithms must assume that
there is some bias on the input messages so that some inputs are more likely than others, i.e. that
there is some unbalanced probability distribution over the possible messages. Most compression
algorithms base this ‚Äúbias‚Äù on the structure of the messages ‚Äì i.e., an assumption that repeated
characters are more likely than random characters, or that large white patches occur in ‚Äútypical‚Äù
images. <strong>Compression is therefore all about probability</strong>.‚Äù</p>

<p>When describing compression algorithms, the paper proposes to distinguish between the <em>coder</em> and the <em>model</em>. The model refers to an estimation of the distribution for the compressed tokens or characters in the message. For instance when compressing an image, we may assume it is more likely for neighboring pixels to share similar colors. The coder is the procedure that encodes data, typically by assigning shorter codes to more likely tokens, and longer ones to the ones thought to be least likely.</p>

<p>It can be shown that the best compression rate possible would be using only as many bits per token as their entropy. As we chunk more characters into ‚Äútokens‚Äù we could get more compression per bit (for instance modeling the string AABBBAAAA as using the tokens AA, AB, BA, BB instead of just A and B).</p>

<p>There is also conditional entropy (H(s|c)): the entropy of the distribution of p(s|c), weighted by the distribution of c over all possible contexts and s over all possible messages.</p>

<p><img src="image/compression1.png" alt="" loading="lazy" /></p>

<p>It can be shown that H(s|c) &lt;= H(s) and the bound is only tight if context and messages are completely independent. An example of context could be the previous n pixels before the current one, or surrounding n words, etc.</p>

<h3 id="huffman-codes">Huffman Codes</h3>

<p>Huffman codes are optimal prefix codes generated from a set of probabilities by a particular algorithm, the Huffman Coding Algorithm.</p>

<p>‚ÄúThe Huffman algorithm is very simple and is most easily described in terms of how it generates
the prefix-code tree.‚Äù</p>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>Start with a forest of trees, one for each message (=token). Each tree contains a single vertex with
weight wi = pi.

Repeat until only a single tree remains:
	1) Select two trees with the lowest weight roots (w1 and w2). 
	2) Combine them into a single tree by adding a new root with weight w1+w2,
	 and making the two trees its children. 
	 It does not matter which is the left or right child, 
	 but our convention will be to put the lower weight root on the left if w1 != w2.

</code></pre></div></div>

<p>If I‚Äôm seeing this correctly, the most likely codes will end up nearer to the final root, and the least likely ones closer to the leaves. The algorithm is greedy in a way, as it always links the two least likely contenders until there is a single tree.</p>

<p>‚ÄúFor a code of size <em>n</em> this algorithm will require <em>n‚àí1</em> steps since every complete binary tree with
n leaves has <em>n‚àí1</em> internal nodes, and each step creates one internal node. If we use a priority queue
with <em>O(log n)</em> time insertions and find-mins (e.g., a heap) the algorithm will run in <em>O(n log n)</em> time.
The key property of Huffman codes is that they generate optimal prefix codes.‚Äù</p>

<p>Example:</p>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>a .2, b .3, c .3, d .1, e .1

=&gt;
t(d e) .2
a .2

=&gt;
t(a , t(d, e)) .4
t(b, c) .6

=&gt;
t( t(a , t(d, e)) , t(b, c) )
</code></pre></div></div>

<p>Even though all Huffman codes have the same average (minimum) length, it can be good if average message variance is also reduced (for buffering, speed guarantees, etc.).</p>

<p>To ensure this, a simple modification is breaking ties when picking which trees to merge using the two earliest created nodes. All leaves are assumed to have been created first. So if 3 nodes tie in weight, we join the two that were created earlier first. This way, trees diverge less from the average length.</p>

<h3 id="arithmetic-coding">Arithmetic Coding</h3>

<p><img src="image/compression2.png" alt="" loading="lazy" />
<img src="image/compression3.png" alt="" loading="lazy" /></p>

<p>This method seems impractical due to floating point arithmetic‚Äôs quirks.</p>

<h3 id="applications-of-probability-coding">Applications of Probability Coding</h3>

<p>The simplest message distribution model we can make is based on counting. This is unsophisticated and most likely suboptimal.</p>

<p>More sophisticated models are used in real-world applications. All these techniques take advantage of the ‚Äúcontext‚Äù in some way.</p>

<p>This can either be done by</p>
<ul>
  <li><strong>Transforming the data before coding</strong> (e.g., run-length coding, move-to-front coding, and residual coding)</li>
  <li><strong>Directly using conditional probabilities based on a context</strong> (JBIG and PPM).</li>
</ul>

<p><strong>Run Length Coding</strong>: In this coding procedure, a sequence is coded as a sequence of tuples, repetitions where repeated symbols are summed up. E.g. aaaabb =&gt; a;4,b;2. The tuples are usually Huffman encoded later, to compress things even further.</p>

<p><strong>Move-To-Front Coding</strong>: We start with a preordered alphabet, and for each character in the message we a) shift that character to the beginning of the alphabet and b) output how many positions it moved. Hopefully the same characters tend to cluster together and therefore most times we will output small values.</p>

<p><em>Example</em> : Think of an image, where characters are channel values. The alphabet has 256 values, and since similar pixels have similar colors channels may repeat. Maybe if we combine it with run-length so it goes closer to 0? It wouldn‚Äôt work with 256\^3 values for colors, I guess, since it‚Äôs such a big alphabet.</p>

<h3 id="residual-coding-jpeg-lossless-ls">Residual Coding: JPEG-Lossless (LS)</h3>

<p>In residual coding, our model outputs a guess for the correct value of the next message, and then we store only the residual (by how much we missed the mark). Hopefully the model will be good, and then the residuals will tend to gather close to 0, reducing entropy. Finally we do a pass of Huffman encoding after this step, and it‚Äôs all done.</p>

<p>For images, we typically divide them into their three channels and compress each separately (as channel values are more correlated and less varied than pixel values).</p>

<p><strong>Context Coding: JBIG</strong> is a very naive autoregressive algorithm, but only scales well to black and white (like fax) images or very low entropy greyscales (think 6 bits). Again, we output probability residuals and huffman encode them first.</p>

<h3 id="context-coding-ppm---prediction-by-partial-matching">Context Coding: PPM - Prediction by Partial Matching</h3>

<p>Variants of this algorithm have consistently given either the best or close to the best compression ratios recently.</p>

<p>We keep a table of last j characters seen, for each j from 0 to k, and occurrences of next character for each (like in a markov chain model). For each character we are encoding, we output its probability given the current model and previous k characters, and then update it with the new information. However if this character has never been seen within this context, we output a probability of finding a new character (estimated as #different characters / total occurrences of this context) and move one level below in the table, to contexts of length k-1. And so on until we reach context 0, which is just individual character probabilities up to now.</p>

<h3 id="lempel-ziv-algorithms">Lempel-Ziv Algorithms</h3>

<p>The Lempel-Ziv algorithms code groups of characters of varying lengths by building a dictionary of previously seen strings.</p>

<p>At the highest level the algorithms can be described as follows. <em>Given a position in a file,
look through the preceeding part of the file to find the longest match to the string starting at the
current position, and output some code that refers to that match. Now move the finger past the
match.</em></p>

<p>This is the algorithm used in gzip, except it also includes information about probabilities for each substring.</p>

<p><strong>Lempel-Ziv 77</strong> is the one used in gzip, and it involves a sliding window.</p>

<p>The LZ77 algorithm and its variants use a sliding window that moves along with the cursor. The
window can be divided into two parts, the part before the cursor, called the dictionary, and the part
starting at the cursor, called the lookahead buffer. The size of these two parts are parameters of the
program and are fixed during execution of the algorithm. The basic algorithm is very simple, and
loops executing the following steps:</p>

<ul>
  <li>Find the longest match of a string starting at the cursor and completely contained in the lookahead buffer to a string starting in the dictionary.</li>
  <li>Output a triple <em>(p, n, c)</em> containing the position p of the occurence in the window, the length
n of the match and the next character <em>c</em> past the match in the buffer.</li>
  <li>Move the cursor n + 1 characters forward.</li>
</ul>

<p>A possible improvement is called LZSS variant, which uses two formats: if no match of length &gt;2 is found, it turns on a bit and then outputs the character alone. Else it keeps it off. This way we avoid wasting two fields on an empty match.</p>

<p>Gzip uses separate huffman codes for the offset, the length and the character. Each uses adaptive Huffman codes.</p>

<p>It also makes matching <strong>non-greedy</strong>: It tries matching the string beginning from the next character besides the current one, then if that match is longer than the greedy one, it will append a single character and the second, longer match‚Äôs tuple.</p>

<p>Pseudocode for LZW is as follows (note that this version doesn‚Äôt do LZSS, or non-greediness).</p>

<p><img src="image/compression4.png" alt="" loading="lazy" /></p>

<p>The dictionary operations can be implemented very efficiently using a trie, or just a hash table for each prefix if memory is an issue (which happens quick as the trie grows in memory exponentially in the key length -with a base proportional to alphabet size-, and keys can get long).</p>

<h2 id="lossy-compression">Lossy Compression</h2>

<p>In lossy compression, the resulting message may be significantly smaller in size than the original, but after reconstruction a portion of the information is lost.</p>

<p>Thus lossy algorithms can compress data almost arbitrarily efficiently, with human perceived degradation as the constraint.</p>

<p><strong>Vector Quantization</strong>: We assign all vectors in our population to a set of clusters, and map each point to its closest cluster centroid. This allows for a very efficient encoding of, for instance, image pixels (using a reduced palette as I covered in <a href="/dithering">dithering</a>).</p>

<p>For a lossless alternative, we could store each pixel‚Äôs centroid ID plus the residue, which if the data are sufficiently clustered should tend to be small and thus encode efficiently through e.g. Huffman encoding or others.</p>

<p><strong>Transform Coding</strong>: For a set of <em>n</em> values, transforms can
be expressed as an <em>n √ó n</em> matrix <em>T</em>. Multiplying the input by this matrix <em>T</em> gives, the transformed coefficients. Multiplying the coefficients by <em>T^‚àí1</em> will convert the data back to the original form.</p>

<p>For example, the coefficients for the discrete cosine transform (DCT) are:</p>

<p><img src="image/compression5.png" alt="" /></p>

<p>For the purpose of compression, the properties we would like of a transform are (1) to decorrelate the data, (2) have many of the transformed coefficients be small, and (3) have it so that from
the point of view of perception, some of the terms are more important than others (so dropping the unimportant ones is viable).</p>

<h3 id="jpeg">JPEG</h3>

<p>JPEG is a lossy compression scheme for color and gray-scale images.</p>

<p>JPEG is designed so that the loss factor can be tuned by the user to tradeoff image size and
image quality, and is designed so that the loss has the least effect on human perception.</p>

<p>It is optimized for naturalistic images, not line drawings or pictures with big smooth monochromatic surfaces.</p>

<p>The first step of JPEG
compression, which is optional, is to convert these into YIQ color planes.</p>

<p>The Y plane is designed to represent the brightness (luminance) of the image. It
is a weighted average of red, blue and green (0.59 Green + 0.30 Red + 0.11 Blue), weighted according to human eye perception of brightness.</p>

<p>The I (interphase) and Q (quadrature) components represent the color hue (chrominance).</p>

<p>JPEG keeps all pixels for the intensity, but typically down samples the two color planes by a factor of 2 in each dimension (a total factor of 4). This is the first lossy component of JPEG and gives a factor of 2 compression: (1 + 2 * .25)/3 = .5.</p>

<p>Then each plane is divided into 8x8 blocks, to each of which we apply a cosine
transform across both dimensions. This returns an 8x8 block of 8-bit frequency terms. So far this
does not introduce any loss, or compression.</p>

<p>‚ÄúAfter the cosine transform, the next step applied to the blocks is to use uniform scalar quantization on each of the frequency terms. This quantization is controllable based on user parameters and is the main source of information loss in JPEG compression. Since the human eye is more perceptive to certain frequency components than to others, JPEG allows the quantization scaling
factor to be different for each frequency component. The scaling factors are specified using an
8x8 table that simply is used to element-wise divide the 8x8 table of frequency components.‚Äù</p>

<p>The frequency table is then traversed in zig zag, and run length encoded so that there are many similar consecutive values (especially 0, due to obscure transform-related reasons).</p>

<p>This last sequence is compressed with Huffman coding.</p>

<p>A more visual explanation can be found in this <a href="https://www.tutorialspoint.com/dip/Introduction_to_JPEG_compression.htm">introduction to JPEG compression</a>.</p>

<h3 id="mpeg">MPEG</h3>

<blockquote>
  <p>Correlation improves compression. This is a recurring theme in all of the approaches we have seen; the more effectively a technique is able to exploit correlations in the data, the more effectively it will be able to compress that data.</p>
</blockquote>

<p>Each frame in an MPEG image stream is encoded using one of three schemes:</p>

<ul>
  <li><strong>I-frame</strong>, or intra-frame: are coded as isolated images.</li>
  <li><strong>P-frame</strong>, or predictive coded frame, are based on the previous I- or P-frame.</li>
  <li><strong>B-frame</strong>, or bidirectionally predictive coded frame, are based on either or both the previous and next I- or P-frame.</li>
</ul>

<p>In an MPEG stream, I-frames and P-frames
appear in an MPEG stream in simple, chronological order. However, B-frames are moved so that
they appear after their neighboring I- and P-frames. This guarantees that each frame appears after
any frame upon which it may depend. An MPEG encoder can decode any frame by buffering the
two most recent I- or P-frames encountered in the data stream.</p>

<p>Since <strong>I-frames are independent images</strong>, they can be encoded as if they were still images. The
particular technique used by MPEG is a variant of the JPEG technique.</p>

<p>To decode any frame we need only find its closest previous I-frame and go from
there. This is important for allowing reverse playback, skip-ahead, or error-recovery.</p>

<p>To <strong>encode a P-frame</strong>, for each target block in the P-frame the encoder finds a reference block in the previous P- or I-frame that most closely matches it. The reference block need not be aligned on a 16-pixel boundary and can potentially be anywhere in the image. In practice, however, the x-y offset is typically small. The offset is called the motion vector.</p>

<p>Once the match is found, the pixels of the reference block are
subtracted from the corresponding pixels in the target block. <strong>This gives a residual which ideally is close to zero everywhere.</strong> This residual is coded using a scheme similar to JPEG encoding, but will ideally get a much better compression ratio because of the low intensities. In addition to sending the coded residual, the coder also needs to send the motion vector. This vector is Huffman coded.</p>

<blockquote>
  <p>The motivation for searching other locations in the reference image for a match is to allow for the efficient encoding of motion.</p>
</blockquote>

<p>In practice, the search for good matches for each target block is the most computationally
expensive part of MPEG encoding. Decoding however is cheap.</p>

<p><strong>B-frames look for reusable data in both directions.</strong> The overall technique is very similar to that
used in P-frames, but instead of just searching in the previous I- or P-frame for a match, it also
searches in the next I- or P-frame. This works for cases where, for instance, an object is occluded and appears from behind another, then moves and hides behind a second one or disappears out of scene.</p>

<p>The coder needs to send some information on which reference(s) is (are)
used, and potentially needs to send two motion vectors, if it chooses to average next and previous I/P- frame.</p>


</div>
<a href='https://ko-fi.com/R6R3F4NIO' target='_blank' rel="noopener noreferrer nofollow">
  <img style='border:0px;height:4em;width:auto;' src='https://cdn.ko-fi.com/cdn/kofi5.png?v=3' border='0' alt='Buy Me a Coffee at ko-fi.com' loading='lazy'/></a>
  <p style='text-align: center;'>
  <a href="https://twitter.com/intent/tweet?text=Introduction to Data Compression&url=https://strikingloo.github.io/wiki/data-compression%2F%3Futm_source%3Dtwitter%26utm_medium%3Dsocial&via=strikingLoo" title="Share on Twitter!">[<svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 310 310" height="1em" width="1em" rel="noopener noreferrer nofollow"><path fill="#1DA1F2" d="M302.973 57.388a117.512 117.512 0 01-14.993 5.463 66.276 66.276 0 0013.494-23.73 5 5 0 00-7.313-5.824 117.994 117.994 0 01-34.878 13.783c-12.381-12.098-29.197-18.983-46.581-18.983-36.695 0-66.549 29.853-66.549 66.547 0 2.89.183 5.764.545 8.598C101.163 99.244 58.83 76.863 29.76 41.204a5.001 5.001 0 00-8.196.642c-5.896 10.117-9.013 21.688-9.013 33.461 0 16.035 5.725 31.249 15.838 43.137a56.37 56.37 0 01-8.907-3.977 5 5 0 00-7.427 4.257c-.007.295-.007.59-.007.889 0 23.935 12.882 45.484 32.577 57.229a57.372 57.372 0 01-5.063-.735 4.998 4.998 0 00-5.699 6.437c7.29 22.76 26.059 39.501 48.749 44.605-18.819 11.787-40.34 17.961-62.932 17.961a120.4 120.4 0 01-14.095-.826 5 5 0 00-3.286 9.174c29.023 18.609 62.582 28.445 97.047 28.445 67.754 0 110.139-31.95 133.764-58.753 29.46-33.421 46.356-77.658 46.356-121.367 0-1.826-.028-3.67-.084-5.508 11.623-8.757 21.63-19.355 29.773-31.536a5 5 0 00-6.182-7.351z"></path></svg>Share on twitter]</a></p>

<template id="post-delayed-content">

<div class="backButton">
<a href="https://twitter.com/intent/tweet?text=Introduction to Data Compression&url=https://strikingloo.github.io/wiki/data-compression%2F%3Futm_source%3Dtwitter%26utm_medium%3Dsocial&via=strikingLoo" id='tweetThis' title="Share on Twitter!" rel="noopener noreferrer nofollow">[<svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 310 310" height="1em" width="1em"><path fill="#1DA1F2" d="M302.973 57.388a117.512 117.512 0 01-14.993 5.463 66.276 66.276 0 0013.494-23.73 5 5 0 00-7.313-5.824 117.994 117.994 0 01-34.878 13.783c-12.381-12.098-29.197-18.983-46.581-18.983-36.695 0-66.549 29.853-66.549 66.547 0 2.89.183 5.764.545 8.598C101.163 99.244 58.83 76.863 29.76 41.204a5.001 5.001 0 00-8.196.642c-5.896 10.117-9.013 21.688-9.013 33.461 0 16.035 5.725 31.249 15.838 43.137a56.37 56.37 0 01-8.907-3.977 5 5 0 00-7.427 4.257c-.007.295-.007.59-.007.889 0 23.935 12.882 45.484 32.577 57.229a57.372 57.372 0 01-5.063-.735 4.998 4.998 0 00-5.699 6.437c7.29 22.76 26.059 39.501 48.749 44.605-18.819 11.787-40.34 17.961-62.932 17.961a120.4 120.4 0 01-14.095-.826 5 5 0 00-3.286 9.174c29.023 18.609 62.582 28.445 97.047 28.445 67.754 0 110.139-31.95 133.764-58.753 29.46-33.421 46.356-77.658 46.356-121.367 0-1.826-.028-3.67-.084-5.508 11.623-8.757 21.63-19.355 29.773-31.536a5 5 0 00-6.182-7.351z"></path></svg>]</a>
<br/>
<a href="/blog/" id='backToBlog' title="Back to blog" rel="noopener noreferrer">[‚Üê]</a>
</div>
</template>
<script>
const headings = document.querySelectorAll('h2[id],h3[id]');
for (var heading of headings) {
    heading.innerHTML = `<a href=#${heading.id}>${heading.innerHTML}</a>`;
}
function externalLinks() { for(var c = document.getElementsByTagName("a"), a = 0;a < c.length;a++) { var b = c[a]; b.getAttribute("href") && b.hostname !== location.hostname && (b.target = "_blank") } }
externalLinks();

function renderBottomButtons(){
  const templateNode = document.getElementById('post-delayed-content')
  const templateContentClone = templateNode.content.cloneNode(true) // perform a deep copy
  document.body.appendChild(templateContentClone)
}

function scrollEventHandler(){
 const scrollOffset = window.pageYOffset
 const browserViewHeight = window.innerHeight
 if (scrollOffset > browserViewHeight/3) {
    console.log('done')
    renderBottomButtons();
    window.removeEventListener('scroll', scrollEventHandler)
 }
}
window.addEventListener('scroll', scrollEventHandler)
</script>

<meta name="twitter:card" content="summary_large_image" />
<meta name="twitter:site" content="@StrikingLoo" />
<meta name="twitter:title" content="Introduction to Data Compression" />
<meta name="twitter:description" content="Notes on 'Introduction to Data Compression' by Guy E. Blelloch, Computer Science Department, Carnegie Mellon University." />

<meta name="twitter:image:src" content="https://strikingloo.github.io/resources/book-tw.jpg"/>
<meta property="og:image" content="https://strikingloo.github.io/resources/preview-image-terrarium.png"/>

			
			</div>
			<footer>
	    		<ul>
	        		<li><a href="mailto:lucianostrika44@gmail.com" rel="me" title="email me">‚úâÔ∏è</a></li>
	        		<li><a href="https://github.com/strikingloo" rel="me noopener noreferrer nofollow" title="GitHub"><svg viewBox="0 0 438.549 438.549" xmlns="http://www.w3.org/2000/svg" height="1em" width="1em"><path fill="#0F3D3E" d="M409.132 114.573c-19.608-33.596-46.205-60.194-79.798-79.8-33.598-19.607-70.277-29.408-110.063-29.408-39.781 0-76.472 9.804-110.063 29.408-33.596 19.605-60.192 46.204-79.8 79.8C9.803 148.168 0 184.854 0 224.63c0 47.78 13.94 90.745 41.827 128.906 27.884 38.164 63.906 64.572 108.063 79.227 5.14.954 8.945.283 11.419-1.996 2.475-2.282 3.711-5.14 3.711-8.562 0-.571-.049-5.708-.144-15.417a2549.81 2549.81 0 01-.144-25.406l-6.567 1.136c-4.187.767-9.469 1.092-15.846 1-6.374-.089-12.991-.757-19.842-1.999-6.854-1.231-13.229-4.086-19.13-8.559-5.898-4.473-10.085-10.328-12.56-17.556l-2.855-6.57c-1.903-4.374-4.899-9.233-8.992-14.559-4.093-5.331-8.232-8.945-12.419-10.848l-1.999-1.431c-1.332-.951-2.568-2.098-3.711-3.429-1.142-1.331-1.997-2.663-2.568-3.997-.572-1.335-.098-2.43 1.427-3.289s4.281-1.276 8.28-1.276l5.708.853c3.807.763 8.516 3.042 14.133 6.851 5.614 3.806 10.229 8.754 13.846 14.842 4.38 7.806 9.657 13.754 15.846 17.847 6.184 4.093 12.419 6.136 18.699 6.136s11.704-.476 16.274-1.423c4.565-.952 8.848-2.383 12.847-4.285 1.713-12.758 6.377-22.559 13.988-29.41-10.848-1.14-20.601-2.857-29.264-5.14-8.658-2.286-17.605-5.996-26.835-11.14-9.235-5.137-16.896-11.516-22.985-19.126-6.09-7.614-11.088-17.61-14.987-29.979-3.901-12.374-5.852-26.648-5.852-42.826 0-23.035 7.52-42.637 22.557-58.817-7.044-17.318-6.379-36.732 1.997-58.24 5.52-1.715 13.706-.428 24.554 3.853 10.85 4.283 18.794 7.952 23.84 10.994 5.046 3.041 9.089 5.618 12.135 7.708 17.705-4.947 35.976-7.421 54.818-7.421s37.117 2.474 54.823 7.421l10.849-6.849c7.419-4.57 16.18-8.758 26.262-12.565 10.088-3.805 17.802-4.853 23.134-3.138 8.562 21.509 9.325 40.922 2.279 58.24 15.036 16.18 22.559 35.787 22.559 58.817 0 16.178-1.958 30.497-5.853 42.966-3.9 12.471-8.941 22.457-15.125 29.979-6.191 7.521-13.901 13.85-23.131 18.986-9.232 5.14-18.182 8.85-26.84 11.136-8.662 2.286-18.415 4.004-29.263 5.146 9.894 8.562 14.842 22.077 14.842 40.539v60.237c0 3.422 1.19 6.279 3.572 8.562 2.379 2.279 6.136 2.95 11.276 1.995 44.163-14.653 80.185-41.062 108.068-79.226 27.88-38.161 41.825-81.126 41.825-128.906-.01-39.771-9.818-76.454-29.414-110.049z"></path></svg></a></li>
			        <li><a href="https://twitter.com/intent/follow?screen_name=strikingloo" rel="me noopener noreferrer nofollow" title="twitter"><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 310 310" height="1em" width="1em"><path fill="#0F3D3E" d="M302.973 57.388a117.512 117.512 0 01-14.993 5.463 66.276 66.276 0 0013.494-23.73 5 5 0 00-7.313-5.824 117.994 117.994 0 01-34.878 13.783c-12.381-12.098-29.197-18.983-46.581-18.983-36.695 0-66.549 29.853-66.549 66.547 0 2.89.183 5.764.545 8.598C101.163 99.244 58.83 76.863 29.76 41.204a5.001 5.001 0 00-8.196.642c-5.896 10.117-9.013 21.688-9.013 33.461 0 16.035 5.725 31.249 15.838 43.137a56.37 56.37 0 01-8.907-3.977 5 5 0 00-7.427 4.257c-.007.295-.007.59-.007.889 0 23.935 12.882 45.484 32.577 57.229a57.372 57.372 0 01-5.063-.735 4.998 4.998 0 00-5.699 6.437c7.29 22.76 26.059 39.501 48.749 44.605-18.819 11.787-40.34 17.961-62.932 17.961a120.4 120.4 0 01-14.095-.826 5 5 0 00-3.286 9.174c29.023 18.609 62.582 28.445 97.047 28.445 67.754 0 110.139-31.95 133.764-58.753 29.46-33.421 46.356-77.658 46.356-121.367 0-1.826-.028-3.67-.084-5.508 11.623-8.757 21.63-19.355 29.773-31.536a5 5 0 00-6.182-7.351z"></path></svg></a></li>
			        <li><a href="http://www.linkedin.com/in/luciano-strika" rel="me noopener noreferrer nofollow" title="linkedin"><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 310 310" height="1em" width="1em"><path fill="#0F3D3E" d="M72.16 99.73H9.927a5 5 0 00-5 5v199.928a5 5 0 005 5H72.16a5 5 0 005-5V104.73a5 5 0 00-5-5zM41.066.341C18.422.341 0 18.743 0 41.362 0 63.991 18.422 82.4 41.066 82.4c22.626 0 41.033-18.41 41.033-41.038C82.1 18.743 63.692.341 41.066.341zM230.454 94.761c-24.995 0-43.472 10.745-54.679 22.954V104.73a5 5 0 00-5-5h-59.599a5 5 0 00-5 5v199.928a5 5 0 005 5h62.097a5 5 0 005-5V205.74c0-33.333 9.054-46.319 32.29-46.319 25.306 0 27.317 20.818 27.317 48.034v97.204a5 5 0 005 5H305a5 5 0 005-5V194.995c0-49.565-9.451-100.234-79.546-100.234z"></path></svg></a></li>
			        <li><a href="/resources/Luciano_Strika.pdf">CV</a></li>
				</ul>
				<p><i>Built with ‚ù§Ô∏è by <a href="https://strikingloo.github.io/">Strikingloo</a>.</i></p>
			</footer>
			

			

			
			<link rel="preload" href="/css/non-critical-post-min.css" as="style" onload="this.onload=null;this.rel='stylesheet'">
			<noscript><link rel="stylesheet" href="/css/non-critical-post-min.css"></noscript>
        	
		</body>
	</html>
