<!DOCTYPE html>
	<html lang="en">
		<head>
		<meta charset="utf-8">
		<meta name="viewport" content="width=device-width, initial-scale=1.0">
		<link rel="icon" type="image/svg+xml" href="data:image/svg+xml,<svg xmlns=%22http://www.w3.org/2000/svg%22 width=%22256%22 height=%22256%22 viewBox=%220 0 100 100%22><rect width=%22100%22 height=%22100%22 rx=%2220%22 fill=%22%23d8eaeb%22></rect><text x=%2250%%22 y=%2250%%22 dominant-baseline=%22central%22 text-anchor=%22middle%22 font-size=%2293%22>üå≥</text></svg>" />
            <title>K-Means Clustering for Magic: the Gathering Decks - Card Recommendation</title>
			<link rel="canonical" href="https://strikingloo.github.io/k-means-clustering-magic-the-gathering">
			  <meta name="description" content="Will the clusters that k-Means Clustering finds in a dataset of decks predict the meta? I apply unsupervised learning to find out.">
  			<meta property="og:site_name" content="K-Means Clustering for Magic: the Gathering Decks - Card Recommendation">

        	
        	<link rel="stylesheet" type="text/css" href="/css/post-min.css">
        	

			<script async src="https://www.googletagmanager.com/gtag/js?id=UA-52642322-5"></script>

			<script>
			  window.dataLayer = window.dataLayer || [];
			  function gtag(){dataLayer.push(arguments);}
			  gtag('js', new Date());

			  gtag('config', 'UA-52642322-5');
			</script>
			
			  <meta property="og:description" content="Will the clusters that k-Means Clustering finds in a dataset of decks predict the meta? I apply unsupervised learning to find out.">
			
	  		<meta property="og:locale" content="en_US">
	  		
			  <meta property="og:title" content="K-Means Clustering for Magic: the Gathering Decks - Card Recommendation">
			  <meta property="og:type" content="article">
		  	  <meta property="article:published_time" content="2019-04-14T00:00:00+00:00">
		      <meta property="article:author" content="/">
		  	
		  	
  				<meta property="og:url" content="https://strikingloo.github.io/k-means-clustering-magic-the-gathering">
  			
  			<meta content="index,follow" name="robots"><!-- All Search Engines -->
  			<meta content="index,follow" name="googlebot"><!-- Google Specific -->
  			<meta name="robots" content="max-image-preview:large">

		</head>
		<body>
			<div class="head-banner">
			<p>Strikingloo</p>
			<nav>
	    		<ul>
	        		<li><a href="/">Home</a></li>
		        	<li><a href="/about/">About</a></li>
	        		<li><a href="/wiki/">Wiki</a></li>
	        		<li><a href="/blog/">Blog </a></li>
	    		</ul>
			</nav>
			<div style="clear: both;"></div>
		    </div>

			<div class="container">
			
			<h1>K-Means Clustering for Magic: the Gathering Decks - Card Recommendation</h1>
<p class="meta">14 Apr 2019 - importance: 7 </p>



<p class="abstract" style="background-color: #E2DCC8;
border:2px solid;
font-style:italic;
margin:5%;
text-align: center;
padding:2%;"> I apply K-Means Clustering to a Magic: The Gathering deck dataset and find whether it predicts the meta. Included is an explanation of how k-means works. This is a post from my old blog, so some parts may not represent my current opinions.</p>


<div class="post">
  <p>Unsupervised Learning has been called the closest thing we have to ‚Äúactual‚Äù Artificial Intelligence, in the sense of General AI, with K-Means Clustering one of its simplest, but most powerful applications.</p>

<p>I am not here to discuss whether those claims are true or not. I will however state, that I am often amazed by how well unsupervised learning techniques, even the most rudimentary, capture patterns in the data that I would expect only people to find.</p>

<p>Today we‚Äôll apply unsupervised learning on a Dataset I gathered myself. It‚Äôs a database of professional Magic: The Gathering decks that I crawled from <a href="https://mtgtop8.com/">mtgtop8.com,</a> an awesome website if you‚Äôre into Magic: the Gathering.</p>

<p>I scraped the MtgTop8 data from a few years of tournaments, and they‚Äôre all available to be consumed in <a href="https://github.com/StrikingLoo/mtgProject">this GitHub repository</a>.</p>

<p>If you‚Äôre not into the game, or even if you‚Äôve never even played it, <strong>don‚Äôt worry</strong>: it won‚Äôt get in the way too much, as I will just explain the theoretical side of K-means Clustering and show you how to apply it using Dask, the parallel computing Python framework. If you are into the game, then you‚Äôre gonna love the examples.</p>

<h2 id="k-means-clustering">K-Means Clustering</h2>

<p>The algorithm we will look into today is called ‚ÄòK-means clustering‚Äô. It provides a way to characterize and categorize data if we don‚Äôt really know how to separate it before hand.</p>

<h3 id="why-do-we-need-unsupervised-learning">Why do we need Unsupervised Learning?</h3>

<p>What do I mean by Unsupervised Learning? Suppose you had a set of pictures of cats and dogs. You could train a supervised Machine Learning model to classify the pictures into either category.</p>

<p>However, imagine you have a big, complex dataset of things you don‚Äôt know a lot about. For instance, you could have data about the light spectrum produced by different planets, and be looking for a way to group them into categories.</p>

<p>For another example, you could have loads of genetic data from many different organisms, and wish to define which ones belong to the same genus or families in an intuitive way.</p>

<p>Or, in our case, we could have 777 different Magic: The Gathering decks, using over 600 different cards (yeah, the professional meta is not <em>that</em> diverse), and want to train a machine learning model so that it understands which cards work well together and which ones don‚Äôt.</p>

<p>Now imagine you had to do this task, and you had no idea how to play this game. Wouldn‚Äôt it be nice if someone had invented an algorithm to cluster data together if they look similar, without you having to provide a definition for ‚Äòsimilar‚Äô? That‚Äôs what clustering, and k-means clustering in particular, are all about.</p>

<p>Now that‚Äôs done, I hope you‚Äôre motivated, because it‚Äôs time to get our hands dirty with some theory.</p>

<h3 id="how-does-k-means-clustering-work">How does K-Means Clustering work?</h3>

<p>K-Means Clustering receives a single hyperparameter: <em>k</em>, which specifies how many clusters we want to categorize our data into.</p>

<p>The clusters won‚Äôt necessarily all have the same quantity of instances. However, they should each characterize a specific subset of our data. How will we achieve this? Let‚Äôs find out.</p>

<p>First, the input for this algorithm needs to be a set of vectors. That is, all your features should be numerical, and in the same order. If you had any categorical features, my advice would be to use one-hot encode: convert each categorical variable into a vector of n-elements: one for each possible category, all set to 0 except the one for the given category.</p>

<p>What the algorithm will do is initiate <em>k</em> random ‚Äòcentroids‚Äô -points in the space defined by the dimensions of the dataset‚Äôs elements-, and then it will:</p>

<ul>
  <li>Assign each element to the centroid closest to it.</li>
  <li>Remap the centroid to the point lying on the average of all the elements assigned to it.</li>
  <li>Repeat steps 1 and 2, until convergence (or a stopping condition, such as doing N iterations for a given N) is met. Convergence is usually defined as no instances changing their cluster label from one iteration to the next.</li>
</ul>

<p>In the end, each element will have been assigned to one of <em>k</em> clusters, such that the elements in the same cluster all lie closest to it.</p>

<p>Here is a gif showing the algorithm in action, courtesy of Wikimedia Commons.</p>

<p><img src="resources/post_image/k-means-convergence.gif" alt="K-means convergence, Chire, CC BY-SA 4.0 &lt;https://creativecommons.org/licenses/by-sa/4.0&gt;, via Wikimedia Commons" loading="lazy" style="width:60%;height:60%" /></p>

<p>The crosses represent the position of each cluster‚Äôs centroid, and you can see how they start moving until they become stable. Notice also how they move more initially, and less over time.</p>

<h3 id="applications-for-k-means-clustering">Applications for K-means clustering</h3>

<p>Like many other unsupervised learning algorithms, K-means clustering can work wonders if used as a way to generate inputs for a supervised Machine Learning algorithm (for instance, a classifier).</p>

<p>The inputs could be a one-hot encode of which cluster a given instance falls into, or the k distances to each cluster‚Äôs centroid.</p>

<p>For this project however, what we‚Äôll be developing will be a (somewhat rudimentary) recommender system which will, given an instance, return elements appearing on the same cluster.</p>

<h2 id="using-dasks-k-means-clustering-in-python">Using Dask‚Äôs K-means Clustering in Python</h2>

<p>Having defined the concepts for this project, let‚Äôs now begin the practical part. The code is available in the Jupyter Notebook on <a href="https://github.com/StrikingLoo/MtGRecommender/">this repository</a>.</p>

<h3 id="processing-the-data">Processing the Data</h3>

<p>I stored the decks following this format:</p>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>N card name
M another card name
</code></pre></div></div>

<p>in 777 different <em>.txt</em> files, where each line refers to a card, and the digits before the first space are the number of apparitions for that card in the deck.</p>

<p>In order to transform them into a more manageable format -I‚Äôll be using a list of tuples (Int, String) for each deck, each tuple a card-, this is what we‚Äôll do:</p>

<script src="https://gist.github.com/StrikingLoo/45f3c1bd30753876dcb9235118e1eeb1.js"></script>

<p>This is what a deck looks like now.</p>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>[(4, 'Ancient Ziggurat'), (4, 'Cavern of Souls'), (4, 'Horizon Canopy'),
 (1, 'Plains'), (2, 'Seachrome Coast'), (4, 'Unclaimed Territory'),
  (4, 'Champion of the Parish'), (1, 'Dark Confidant') ...]
</code></pre></div></div>

<p>Where each tuple represents a card (yes, those are real card names), and how many times it appears.</p>

<p>Since we want to map each deck to a vector, it seems intuitive to just</p>

<ul>
  <li>Turn them into a list, with one element for each different card in the whole MtgTop8 dataset.</li>
  <li>Set each component to the number of apparitions for the corresponding card (with all the components corresponding to cards that do not appear in the deck set to 0).</li>
</ul>

<p>To do that, let‚Äôs get all the different cards that appear in all the decks.</p>

<script src="https://gist.github.com/StrikingLoo/2145782d9c6509f19dc68aa38fc54ed8.js"></script>

<p>And now let‚Äôs use our newfound knowledge about card names to turn all decks into beautiful, consumable vectors.</p>

<script src="https://gist.github.com/StrikingLoo/7e1f38cf47fde3c3cedbed6a7eb2c176.js"></script>

<p>Now all our decks can be easily fed into Dask‚Äôs K-Means Clustering algorithm, and we can play with the output.</p>

<p>We could have just used ‚Äòbinary‚Äô vectors, and set the components to 1 if the card appears in the deck, and 0 if it doesn‚Äôt. We could also try that later and see if we get good results too.</p>

<h3 id="applying-k-means-clustering">Applying K-means Clustering</h3>

<p>Now that our data is all neatly mapped to the vector space, actually using Dask‚Äôs K-means Clustering is pretty simple.</p>

<script src="https://gist.github.com/StrikingLoo/251b55817a4777a37ccbc75b8faa0f18.js"></script>

<p>Where the most important part is the <em>n_clusters</em> argument, which I kind of arbitrarily set to 8.</p>

<p>In real life, you may want to experiment with different values. For this particular case, I know MtG has 5 different ‚Äòcolors‚Äô for cards. To prevent the algorithm from just clustering the cards for their colors (which it didn‚Äôt do at all anyway), I chose a number bigger than 5.</p>

<p>The algorithm returns the labels as a Dask Array. I may do an article on how to use those later, but right now I didn‚Äôt want to deal with all that. Also, the MtgTop8 dataset is small enough for that to not matter that much, so I decided to convert it back to a list of integers. Sue me.</p>

<script src="https://gist.github.com/StrikingLoo/40004ecf4733dcfcfdb1e0e78be966ce.js"></script>

<h3 id="exploratory-analysis-lets-see-what-we-got">Exploratory Analysis: Let‚Äôs see what we got</h3>

<p>At first I wanted to check if the results made any sense. This was my first time using K-means Clustering on this dataset, and I wanted to make sure it had learned something valuable. So I just checked which cards were most frequent in the decks from each cluster. The results were, at least to me, astounding. Here‚Äôs what I did to check.</p>

<script src="https://gist.github.com/StrikingLoo/f8df3b441fdefb7808474015b54c4753.js"></script>

<p>If you‚Äôre interested in the results, here‚Äôs a <a href="https://towardsdatascience.com/magic-the-gathering-meets-data-science-2a0367c724fe">separate article about them</a>. I just didn‚Äôt want to mix my M:tG findings with this tutorial so that readers who are into Data Science but not into the game won‚Äôt be bored.
In case you‚Äôre interested, I later wrote about a completely different application for K-Means Clustering: <a href="https://dev.to/strikingloo/k-means-clustering-with-dask-image-filters-for-pictures-of-kittens-ip7">image filters</a>.</p>

<p>I also strongly encourage you to download the notebook from the GitHub project and play with it, it‚Äôs honest fun.</p>

<h3 id="card-recommendations-using-k-means-clustering">Card Recommendations using K-Means Clustering</h3>

<p>Now we made that sanity check, we can proceed with the actual application for all the labels we generated.</p>

<p>There are many ways we could have approached the recommendation problem: given a card, suggest other cards that go well with it, without using any data about the cards except which decks they appear in (that is, no cheating and asking for more data about the cards like color, price, or an expert‚Äôs opinion).</p>

<p>Think for a moment, how would you use the clusters data to generate the recommendations? I‚Äôm sure you could come up with a few ideas.</p>

<p>If what you came up with is not what I‚Äôm about to do, please tell me. Creativity is more fun if it‚Äôs a team effort, and I really want to see what my dear readers come up with.</p>

<p>Finally, here‚Äôs what I did:
<script src="https://gist.github.com/StrikingLoo/d325dea2347f5f48cc0e4c16c2ef5cec.js"></script></p>

<p>As you can see, I omit how many times a card appears on a given deck for this part, and just look at the relative number of apparitions for a card on a given cluster.</p>

<p>I then return the cards with the most similar relative apparitions (defined by Euclidian distance).</p>

<p>If you‚Äôre a Magic: The Gathering player, try out this code and see the results. It makes reasonably good (though kind of conservative) recommendations.</p>

<h2 id="conclusion">Conclusion</h2>

<p>K-Means clustering allowed us to approach a domain without really knowing a whole lot about it, and draw conclusions and even design a useful application around it.</p>

<p>It let us do that by learning the underlying patterns in the data for us, only asking that we gave it the data in the correct format.</p>

<p>I encourage you to play with the code here, and try making your own recommendation‚Äôs system with a different Dataset, or solving some other problem. If you do, please show me your results. I wanna see what you come up with.</p>

<p>In the future, I‚Äôd like to do this same analysis using non-professional decks. That way, I could make a recommendations engine for casual players (like me). I think it would be cool if it worked with almost any card, and not just 642.</p>

<p>If you want to delve deeper into Unsupervised Learning, I can‚Äôt recommend <a href="https://amzn.to/3RSmJwT">Introduction to Statistical Learning</a> enough. That‚Äôs the book I learned about K-Means Clustering from. It‚Äôs also the book thanks to which I finally understood Boosted Trees, though that‚Äôs a tale for another article.</p>

<p><em>Liked this article? Then please follow me on</em> <a href="https://www.twitter.com/strikingloo"><em>Twitter</em></a>. Let me know if you found the article helpful, or if any of it sounds wrong or doesn‚Äôt work._</p>

<p>Happy coding.</p>

</div>
<a href='https://ko-fi.com/R6R3F4NIO' target='_blank' rel="noopener noreferrer nofollow">
  <img style='border:0px;height:4em;width:auto;' src='https://cdn.ko-fi.com/cdn/kofi5.png?v=3' border='0' alt='Buy Me a Coffee at ko-fi.com' loading='lazy'/></a>
  <p style='text-align: center;'>
  <a href="https://twitter.com/intent/tweet?text=K-Means Clustering for Magic: the Gathering Decks - Card Recommendation&url=https://strikingloo.github.io/k-means-clustering-magic-the-gathering%2F%3Futm_source%3Dtwitter%26utm_medium%3Dsocial&via=strikingLoo" title="Share on Twitter!">[<svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 310 310" height="1em" width="1em" rel="noopener noreferrer nofollow"><path fill="#1DA1F2" d="M302.973 57.388a117.512 117.512 0 01-14.993 5.463 66.276 66.276 0 0013.494-23.73 5 5 0 00-7.313-5.824 117.994 117.994 0 01-34.878 13.783c-12.381-12.098-29.197-18.983-46.581-18.983-36.695 0-66.549 29.853-66.549 66.547 0 2.89.183 5.764.545 8.598C101.163 99.244 58.83 76.863 29.76 41.204a5.001 5.001 0 00-8.196.642c-5.896 10.117-9.013 21.688-9.013 33.461 0 16.035 5.725 31.249 15.838 43.137a56.37 56.37 0 01-8.907-3.977 5 5 0 00-7.427 4.257c-.007.295-.007.59-.007.889 0 23.935 12.882 45.484 32.577 57.229a57.372 57.372 0 01-5.063-.735 4.998 4.998 0 00-5.699 6.437c7.29 22.76 26.059 39.501 48.749 44.605-18.819 11.787-40.34 17.961-62.932 17.961a120.4 120.4 0 01-14.095-.826 5 5 0 00-3.286 9.174c29.023 18.609 62.582 28.445 97.047 28.445 67.754 0 110.139-31.95 133.764-58.753 29.46-33.421 46.356-77.658 46.356-121.367 0-1.826-.028-3.67-.084-5.508 11.623-8.757 21.63-19.355 29.773-31.536a5 5 0 00-6.182-7.351z"></path></svg>Share on twitter]</a></p>

<template id="post-delayed-content">

<div class="backButton">
<a href="https://twitter.com/intent/tweet?text=K-Means Clustering for Magic: the Gathering Decks - Card Recommendation&url=https://strikingloo.github.io/k-means-clustering-magic-the-gathering%2F%3Futm_source%3Dtwitter%26utm_medium%3Dsocial&via=strikingLoo" id='tweetThis' title="Share on Twitter!" rel="noopener noreferrer nofollow">[<svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 310 310" height="1em" width="1em"><path fill="#1DA1F2" d="M302.973 57.388a117.512 117.512 0 01-14.993 5.463 66.276 66.276 0 0013.494-23.73 5 5 0 00-7.313-5.824 117.994 117.994 0 01-34.878 13.783c-12.381-12.098-29.197-18.983-46.581-18.983-36.695 0-66.549 29.853-66.549 66.547 0 2.89.183 5.764.545 8.598C101.163 99.244 58.83 76.863 29.76 41.204a5.001 5.001 0 00-8.196.642c-5.896 10.117-9.013 21.688-9.013 33.461 0 16.035 5.725 31.249 15.838 43.137a56.37 56.37 0 01-8.907-3.977 5 5 0 00-7.427 4.257c-.007.295-.007.59-.007.889 0 23.935 12.882 45.484 32.577 57.229a57.372 57.372 0 01-5.063-.735 4.998 4.998 0 00-5.699 6.437c7.29 22.76 26.059 39.501 48.749 44.605-18.819 11.787-40.34 17.961-62.932 17.961a120.4 120.4 0 01-14.095-.826 5 5 0 00-3.286 9.174c29.023 18.609 62.582 28.445 97.047 28.445 67.754 0 110.139-31.95 133.764-58.753 29.46-33.421 46.356-77.658 46.356-121.367 0-1.826-.028-3.67-.084-5.508 11.623-8.757 21.63-19.355 29.773-31.536a5 5 0 00-6.182-7.351z"></path></svg>]</a>
<br/>
<a href="/blog/" id='backToBlog' title="Back to blog" rel="noopener noreferrer">[‚Üê]</a>
</div>
</template>
<script>
const headings = document.querySelectorAll('h2[id],h3[id]');
for (var heading of headings) {
    heading.innerHTML = `<a href=#${heading.id}>${heading.innerHTML}</a>`;
}
function externalLinks() { for(var c = document.getElementsByTagName("a"), a = 0;a < c.length;a++) { var b = c[a]; b.getAttribute("href") && b.hostname !== location.hostname && (b.target = "_blank") } }
externalLinks();

function renderBottomButtons(){
  const templateNode = document.getElementById('post-delayed-content')
  const templateContentClone = templateNode.content.cloneNode(true) // perform a deep copy
  document.body.appendChild(templateContentClone)
}

function scrollEventHandler(){
 const scrollOffset = window.pageYOffset
 const browserViewHeight = window.innerHeight
 if (scrollOffset > browserViewHeight/3) {
    console.log('done')
    renderBottomButtons();
    window.removeEventListener('scroll', scrollEventHandler)
 }
}
window.addEventListener('scroll', scrollEventHandler)
</script>

<meta name="twitter:card" content="summary_large_image" />
<meta name="twitter:site" content="@StrikingLoo" />
<meta name="twitter:title" content="K-Means Clustering for Magic: the Gathering Decks - Card Recommendation" />
<meta name="twitter:description" content="Will the clusters that k-Means Clustering finds in a dataset of decks predict the meta? I apply unsupervised learning to find out." />

<meta name="twitter:image:src" content="https://strikingloo.github.io/resources/post_image/brain.jpg" />
<meta property="og:image" content="https://strikingloo.github.io/resources/post_image/brain.jpg"/>

			
			</div>
			<footer>
	    		<ul>
	        		<li><a href="mailto:lucianostrika44@gmail.com" rel="me" title="email me">‚úâÔ∏è</a></li>
	        		<li><a href="https://github.com/strikingloo" rel="me noopener noreferrer nofollow" title="GitHub"><svg viewBox="0 0 438.549 438.549" xmlns="http://www.w3.org/2000/svg" height="1em" width="1em"><path fill="#0F3D3E" d="M409.132 114.573c-19.608-33.596-46.205-60.194-79.798-79.8-33.598-19.607-70.277-29.408-110.063-29.408-39.781 0-76.472 9.804-110.063 29.408-33.596 19.605-60.192 46.204-79.8 79.8C9.803 148.168 0 184.854 0 224.63c0 47.78 13.94 90.745 41.827 128.906 27.884 38.164 63.906 64.572 108.063 79.227 5.14.954 8.945.283 11.419-1.996 2.475-2.282 3.711-5.14 3.711-8.562 0-.571-.049-5.708-.144-15.417a2549.81 2549.81 0 01-.144-25.406l-6.567 1.136c-4.187.767-9.469 1.092-15.846 1-6.374-.089-12.991-.757-19.842-1.999-6.854-1.231-13.229-4.086-19.13-8.559-5.898-4.473-10.085-10.328-12.56-17.556l-2.855-6.57c-1.903-4.374-4.899-9.233-8.992-14.559-4.093-5.331-8.232-8.945-12.419-10.848l-1.999-1.431c-1.332-.951-2.568-2.098-3.711-3.429-1.142-1.331-1.997-2.663-2.568-3.997-.572-1.335-.098-2.43 1.427-3.289s4.281-1.276 8.28-1.276l5.708.853c3.807.763 8.516 3.042 14.133 6.851 5.614 3.806 10.229 8.754 13.846 14.842 4.38 7.806 9.657 13.754 15.846 17.847 6.184 4.093 12.419 6.136 18.699 6.136s11.704-.476 16.274-1.423c4.565-.952 8.848-2.383 12.847-4.285 1.713-12.758 6.377-22.559 13.988-29.41-10.848-1.14-20.601-2.857-29.264-5.14-8.658-2.286-17.605-5.996-26.835-11.14-9.235-5.137-16.896-11.516-22.985-19.126-6.09-7.614-11.088-17.61-14.987-29.979-3.901-12.374-5.852-26.648-5.852-42.826 0-23.035 7.52-42.637 22.557-58.817-7.044-17.318-6.379-36.732 1.997-58.24 5.52-1.715 13.706-.428 24.554 3.853 10.85 4.283 18.794 7.952 23.84 10.994 5.046 3.041 9.089 5.618 12.135 7.708 17.705-4.947 35.976-7.421 54.818-7.421s37.117 2.474 54.823 7.421l10.849-6.849c7.419-4.57 16.18-8.758 26.262-12.565 10.088-3.805 17.802-4.853 23.134-3.138 8.562 21.509 9.325 40.922 2.279 58.24 15.036 16.18 22.559 35.787 22.559 58.817 0 16.178-1.958 30.497-5.853 42.966-3.9 12.471-8.941 22.457-15.125 29.979-6.191 7.521-13.901 13.85-23.131 18.986-9.232 5.14-18.182 8.85-26.84 11.136-8.662 2.286-18.415 4.004-29.263 5.146 9.894 8.562 14.842 22.077 14.842 40.539v60.237c0 3.422 1.19 6.279 3.572 8.562 2.379 2.279 6.136 2.95 11.276 1.995 44.163-14.653 80.185-41.062 108.068-79.226 27.88-38.161 41.825-81.126 41.825-128.906-.01-39.771-9.818-76.454-29.414-110.049z"></path></svg></a></li>
			        <li><a href="https://twitter.com/intent/follow?screen_name=strikingloo" rel="me noopener noreferrer nofollow" title="twitter"><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 310 310" height="1em" width="1em"><path fill="#0F3D3E" d="M302.973 57.388a117.512 117.512 0 01-14.993 5.463 66.276 66.276 0 0013.494-23.73 5 5 0 00-7.313-5.824 117.994 117.994 0 01-34.878 13.783c-12.381-12.098-29.197-18.983-46.581-18.983-36.695 0-66.549 29.853-66.549 66.547 0 2.89.183 5.764.545 8.598C101.163 99.244 58.83 76.863 29.76 41.204a5.001 5.001 0 00-8.196.642c-5.896 10.117-9.013 21.688-9.013 33.461 0 16.035 5.725 31.249 15.838 43.137a56.37 56.37 0 01-8.907-3.977 5 5 0 00-7.427 4.257c-.007.295-.007.59-.007.889 0 23.935 12.882 45.484 32.577 57.229a57.372 57.372 0 01-5.063-.735 4.998 4.998 0 00-5.699 6.437c7.29 22.76 26.059 39.501 48.749 44.605-18.819 11.787-40.34 17.961-62.932 17.961a120.4 120.4 0 01-14.095-.826 5 5 0 00-3.286 9.174c29.023 18.609 62.582 28.445 97.047 28.445 67.754 0 110.139-31.95 133.764-58.753 29.46-33.421 46.356-77.658 46.356-121.367 0-1.826-.028-3.67-.084-5.508 11.623-8.757 21.63-19.355 29.773-31.536a5 5 0 00-6.182-7.351z"></path></svg></a></li>
			        <li><a href="http://www.linkedin.com/in/luciano-strika" rel="me noopener noreferrer nofollow" title="linkedin"><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 310 310" height="1em" width="1em"><path fill="#0F3D3E" d="M72.16 99.73H9.927a5 5 0 00-5 5v199.928a5 5 0 005 5H72.16a5 5 0 005-5V104.73a5 5 0 00-5-5zM41.066.341C18.422.341 0 18.743 0 41.362 0 63.991 18.422 82.4 41.066 82.4c22.626 0 41.033-18.41 41.033-41.038C82.1 18.743 63.692.341 41.066.341zM230.454 94.761c-24.995 0-43.472 10.745-54.679 22.954V104.73a5 5 0 00-5-5h-59.599a5 5 0 00-5 5v199.928a5 5 0 005 5h62.097a5 5 0 005-5V205.74c0-33.333 9.054-46.319 32.29-46.319 25.306 0 27.317 20.818 27.317 48.034v97.204a5 5 0 005 5H305a5 5 0 005-5V194.995c0-49.565-9.451-100.234-79.546-100.234z"></path></svg></a></li>
			        <li><a href="/resources/Luciano_Strika.pdf">CV</a></li>
				</ul>
				<p><i>Built with ‚ù§Ô∏è by <a href="https://strikingloo.github.io/">Strikingloo</a>.</i></p>
			</footer>
			

			

			
			<link rel="preload" href="/css/non-critical-post-min.css" as="style" onload="this.onload=null;this.rel='stylesheet'">
			<noscript><link rel="stylesheet" href="/css/non-critical-post-min.css"></noscript>
        	
		</body>
	</html>
