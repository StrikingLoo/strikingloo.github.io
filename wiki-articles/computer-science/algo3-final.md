---
layout: post
title: "Algoritmos y Estructuras de Datos III - Notas para el final"
date: 2021-02-22
tags: algo3, data structures, UBA, spanish, espa√±ol, cs, algorithms
description: "Notas para el final de Algo3. Basadas en los apuntes de la teorica. In Spanish."
---

## Algoritmos
Secuencia finita de pasos que terminan en tiempo finito. 
Los pasos deben ser:
- **Precisos** (en su orden)
- **Bien definidos** (deterministicos)
- **Finitos** 

## M√°quina RAM
- Tiene infinitos registros de tama√±o infinito.
- Cada uno accesible en tiempo constante.

Instrucciones disponibles:
- Load, Store, Write, Read (las ultimas dos son para el I/O del algoritmo, las otras para la ram).
- add, sub, mult, div (misma complejidad independiente del tama√±o del numero)
- jmp, jgtz, jz, halt

## Complejidad computacional

Definici√≥n informal: La complejidad de un algoritmo es una funci√≥n que representa el tiempo de ejecuci√≥n en funci√≥n del tama√±o de la entrada del algoritmo.

operacion elemental (O(1)) : no depende del tama√±o del input, solo de la implementaci√≥n.

Simplificamos asumiendo que toda operaci√≥n elemental puede ser ejecutada en una unidad de tiempo. Interesa c√≥mo crece el tiempo de ejecuci√≥n de un algoritmo cuando el tama√±o de las instancias de entrada crece. No interesa el tiempo exacto requerido por cada una de ellas.

**Modelo uniforme** : Cada operaci√≥n b√°sica tiene un tiempo de ejecuci√≥n constante.
**Modelo logar√≠tmico**: El tiempo de ejecuci√≥n de cada operaci√≥n es funci√≥n del tama√±o (cantidad de bits) de los operandos.

##¬†Big O notation
Sii f es O(g), lim n->inf de f/g = c tq c > 0.

## T√©cnicas de dise√±o de algoritmos

Para demostrar la correctitud de un algoritmo tenemos que demostrar que **termina** y que **cumple la especificaci√≥n**.

**Divide and Conquer** : Para obtener un algoritmo eficiente, la medida de los subproblemas debe ser similar y no necesitar resolver mas de una vez el mismo subproblema.

**Backtracking** :  T√©cnica para recorrer sistem√°ticamente todas las posibles configuraciones del espacio de soluciones.
Se recorre el arbol de soluciones parciales potenciales, y se llega a cada hoja siendo una con todos los elementos definidos. Podemos abandonar una rama del arbol prematuramente por criterios de poda: **Factibilidad** (no quedan soluciones posibles en esta rama) u **Optimalidad** (para problemas de optimizaci√≥n: ya no puede haber una soluci√≥n √≥ptima en esta rama).

Para poder hacer podas por factibilidad, tiene que cumplirse el **efecto domin√≥**: Si una soluci√≥n parcial no es viable, sus extensiones tampoco lo ser√°n.

**Dynamic Programming** : 
**Principio de optimalidad de Bellman** : Una soluci√≥n √≥ptima cada subsoluci√≥n es a su vez √≥ptima del subproblema correspondiente.

## Grafos

**Circuito Hamiltoniano** : Pasar por todos los vertices (Hamilton: cientifico victoriano: como paso por todas las ciudades en mi viaje?)

**Subgrafo** : H es subgrafo de G si H tiene un subconjunto de los vertices, y un subconjunto de los edges -que ademas obviamente solo van entre nodos de H-.
**Subgrafo generador** : H mismos vertices que G, pero subconjunto de aristas. 
**Subgrafo inducido**: H mismos aristas que G, si van entre nodos que est√©n en H. Osea, removiste nodos, pero no edges. 

**Grafo Bipartito** : Un grafo G con 2 o m√°s v√©rtices es bipartito sii **no tiene circuitos simples de longitud impar**.
**√Årbol** : Un √°rbol es un grafo conexo sin circuitos simples.
Son equivalentes: 
- G es un √°rbol (un grafo conexo ac√≠clico).
- Existe exactamente un camino simple entre cada par de v√©rtices.
- G es conexo pero toda arista es puente.
- Si se le agregara una arista e a G, G+e tiene exactamente un ciclo, y ese ciclo tiene a e.
- G es un grafo sin circuitos simples y m = n ‚àí 1.
- G es conexo y m = n ‚àí 1.


Sea G un bosque con c componentes conexas. Entonces *m = n ‚àí c*.

**Arbol generador minimo**: Hallar el conjunto de aristas que arman un arbol generador del grafo G que minimizan la suma de los pesos.
Se resuelve con Prim: parto de un vertice cualquiera, v1, creo mi VT = {v1} y en cada paso selecciono la arista de menor costo entre las que tienen un extremo en VT y el otro en V \ VT .
O con Kruskal: Ordeno las aristas de mas chica a mas grande. Tomo en cada paso la siguiente arista que no forme un ciclo en mi grafo. Freno cuando tom√© n-1 aristas -porque es un arbol-. En la practica: cada nodo arranca como su propio componente, y al unir un arista a mi arbol, pinto uno de los nodos del color del otro. Entonces ver que no formo ciclo == ver que ambos nodos del arista no estan en la misma componente -tienen distinto color-. Hermoso.
Prim's Algorithm is faster for dense graphs.

---
##¬†Camino m√≠nimo
Lo resolvemos para digrafos porque un grafo es un caso particular.

### 1 to many:
- **Todos los edges misma distancia** : Usamos el algoritmo para shortest path (BFS)
- **No hay edges negativos** : Algoritmo de Dijkstra (Prim with extra steps). Por cada vertice, va definiendo un dicc con la distancia al origen. Lo actualiza si encuentra una forma de llegar mas corta. El dicc puede hacerse con array (donde buscar el minimo lleva O(n) ) o con min-heap (donde toma m log(n), pero las lookups del heap son n log (n)). O(m log(n) ) es mejor que O(n^2) -implementaci√≥n "naive" de array-, solo si m ~ O(n). Si m ~ O(n^2) (grafo denso) es mucho peor.

### many to many:
- **Floyd's Algorithm** : Funciona con pesos negativos pero **no si hay ciclos negativos**. Es c√∫bico en n. Usa una matriz de distancias que arranca inicializada con los pesos de los edges, y se va actualizando, en cada una de las k iteraciones con "caminos que tengan solo como intermediarios a los primeros k nodos".

##¬†Grafos Hamiltonianos y Eulerianos.
Existen algoritmos polinomiales para saber si un grafo dado tiene un circuito euleriano, no uno hamiltoniano.

**Circuito euleriano**: pasa por **todos las aristas** de G una y s√≥lo una vez. Un **Grafo Euleriano** tiene un ciclo euleriano.

Equivalencias:
- G es Euleriano.
- Todos los v√©rtices tienen grado par.
- Las aristas de G pueden ser particionadas en ciclos simples.

Para **construir** el ciclo: aprovechamos que cada vertice tiene cantidad par de aristas. Partimos de uno cualquiera y avanzamos vertice por vertice. Siempre que entramos a uno podemos salir, pues cantidad par de aristas. Cuando volvemos al vertice inicial, entonces tenemos un ciclo. Si quedan aristas sin explorar en el grafo, repetimos partiendo por cualquier arista que tenga una punta en el ciclo que acabamos de descubrir, y obtenemos otro ciclo. Eventualmente formamos n ciclos que particionan a G, y la intercalaci√≥n de estos es un ciclo (no simple) que pasa una vez por arista.

Un digrafo conexo es euleriano si, y s√≥lo si, para todo nodo v de G se verfica que din(v) = dout(v).

**Circuito hamiltoniano** : pasa por **cada nodo** de G una y solo una vez. Si G tiene un ciclo Hamiltoniano, decimos que es un grafo Hamiltoniano.
El problema es NP-Hard no resuelto, y no tiene una buena caracterizacion.

Sea G un grafo conexo. Si existe W ‚äÇ V tal que G \\ W tiene c componentes conexas con c > \|W\| entonces G no es hamiltoniano.

**teorema de Dirac** : Sea G un grafo conexo tq n >= 3. Si para todo v en V, d(v) >= n/2, entonces **G Hamiltoniano**.
La inversa no es necesariamente cierta. (Ver C_k!)

**Condicion de Clausura** : Por cada par de v√©rtices no adyacentes u y w, unirlos con una arista si d(u)+d(w) >= n. Repetir hasta convergencia. Si el resultado es hamiltoniano, el grafo inicial tambi√©n lo es. Notar que todo grafo completo es hamiltoniano.

## Heuristicas y Metaheuristicas
Problema de Optimizaci√≥n: Determinar una soluci√≥n factible (satisface toda restriccion) que minimice (o maximice) el objetivo.

Decimos que A es un algoritmo  ‚Äì aproximado, con  ‚àà R>0, si para toda instancia se cumple:
|f (x^A) ‚àí f (x‚àó)| ‚â§ |f (x‚àó)|

Por su facilidad de dise√±o e implementaci√≥n, es muy frecuente utilizar procedimientos golosos. Si bien no aseguran que nos brinden una soluci√≥n √≥ptima (y en general no lo hacen), retornan soluciones de calidad aceptables en compensaci√≥n por el esfuerzo computacional que requieren.

Para TSP muchas heur√≠sticas existen que dan resultados ok pero tienen casos patologicos: hacer un kruskal -quedarse cada vez con el edge mas chico factible-, agregar el eje mas peque√±o posible cada vez -greedy-, o armar un MST del grafo y recorrerlo para conseguir un camino Hamiltoniano. Esta ultima es 1-aproximada si el grafo cumple la desigualdad triangular -es euclideano-. 

Podemos ademas definir "vecindades" para nuestras soluciones: formas de generar soluciones cercanas en el espacio de soluciones, factibles, que podemos comparar para ver si hay ganancia tomandolas. Un ejemplo es k-opt: tomo k nodos y sus sucesores, y roto los ejes seleccionados. E.g., remuevo (i, i+1) y (j, j+1) y agrego (j, i+1), (i, j+1), formando 2-opt. Esto es cuadratico-ish. Definitivamente polinomico.

Esto nos da la noci√≥n de √≥ptimo local: una soluci√≥n que no tiene vecinos mejores. 

**B√∫squeda Local** : buscar un optimo local haciendo un gradient descent discreto: hago alguna permutaci√≥n hacia otra soluci√≥n de la vecindad que mejore mi soluci√≥n candidata, repetidas veces hasta que no pueda mejorarla mas con esta permutacion. E.g.: arranco con un ciclo feo para TSP y voy haciendo 2-opt greedily hasta llegar a la mejor posible. Podes buscar el optimo local de la vecindad cada vez, o solo ir siempre en direcciones que mejoren.

## Metaheuristicas
Buscan mejorar la busqueda local tradicional para no quedar varados en minimos locales. Pueden ser mas o menos simples, y usar memoria en vez de solo mirar vecinos.

**Busqueda Tab√∫** : Memoriza T soluciones visitadas, y las elimina de las opciones V\* en N(s) para explorar.  Clasifica como tab√∫ ciertos atributos de las soluciones (e.g., alguna arista en un TSP).
Se detiene el algoritmo por criterios de parada: cantidad de iteraciones, falta de soluciones mejores, solucion optima global hallada (si se sabe por teoria). 

Solemos usar metaheuristicas para resolver problemas NP-Hard, por falta de algoritmos exactos que los resuelvan en tiempo polinomico. 


