<!DOCTYPE html>
	<html lang="en">
		<head>
		<meta charset="utf-8">
		<meta name="viewport" content="width=device-width, initial-scale=1.0">
		<link rel="icon" type="image/svg+xml" href="data:image/svg+xml,<svg xmlns=%22http://www.w3.org/2000/svg%22 width=%22256%22 height=%22256%22 viewBox=%220 0 100 100%22><rect width=%22100%22 height=%22100%22 rx=%2220%22 fill=%22%23d8eaeb%22></rect><text x=%2250%%22 y=%2250%%22 dominant-baseline=%22central%22 text-anchor=%22middle%22 font-size=%2293%22>üå≥</text></svg>" />
            <title>Evolution through Large Models, OpenAI</title>
			<link rel="canonical" href="https://strikingloo.github.io/wiki/evolution-through-large-models">
			  <meta name="description" content="Notes on the ELM paper, which uses a three-step invention pipeline combining LLM mutators, MAPElites (a genetic algorithm) and RL to design racing robots.">
  			<meta property="og:site_name" content="Evolution through Large Models, OpenAI">

        	
        	<link rel="stylesheet" type="text/css" href="/css/post-min.css">
        	

			<script async src="https://www.googletagmanager.com/gtag/js?id=UA-52642322-5"></script>

			<script>
			  window.dataLayer = window.dataLayer || [];
			  function gtag(){dataLayer.push(arguments);}
			  gtag('js', new Date());

			  gtag('config', 'UA-52642322-5');
			</script>
			
			  <meta property="og:description" content="Notes on the ELM paper, which uses a three-step invention pipeline combining LLM mutators, MAPElites (a genetic algorithm) and RL to design racing robots.">
			
	  		<meta property="og:locale" content="en_US">
	  		
			  <meta property="og:title" content="Evolution through Large Models, OpenAI">
			  <meta property="og:type" content="article">
		  	  <meta property="article:published_time" content="2022-06-22T00:00:00-03:00">
		      <meta property="article:author" content="http://localhost:4000/">
		  	
		  	
  				<meta property="og:url" content="https://strikingloo.github.io/wiki/evolution-through-large-models">
  			
  			<meta content="index,follow" name="robots"><!-- All Search Engines -->
  			<meta content="index,follow" name="googlebot"><!-- Google Specific -->
  			<meta name="robots" content="max-image-preview:large">

		</head>
		<body>
			<div class="head-banner">
			<p>Strikingloo</p>
			<nav>
	    		<ul>
	        		<li><a href="/">Home</a></li>
		        	<li><a href="/about/">About</a></li>
	        		<li><a href="/wiki/">Wiki</a></li>
	        		<li><a href="/blog/">Blog </a></li>
	    		</ul>
			</nav>
			<div style="clear: both;"></div>
		    </div>

			<div class="container">
			
			<h1>Evolution through Large Models, OpenAI</h1>
<p class="meta">22 Jun 2022 - importance: 7 </p>




<div class="post">
  <p><a href="https://arxiv.org/pdf/2206.08896.pdf">https://arxiv.org/pdf/2206.08896.pdf</a></p>

<p>Evolution through Large Models by OpenAI</p>

<p>From Abstract:
‚ÄúThis paper pursues the insight that large language models (LLMs)
trained to generate code can vastly improve the effectiveness of mutation
operators applied to programs in genetic programming (GP). Because such
LLMs benefit from training data that includes sequential changes and
modifications, they can approximate likely changes that humans would
make. To highlight the breadth of implications of such evolution through
large models (ELM), in the main experiment ELM combined with MAPElites generates hundreds of thousands of functional examples of Python
programs that output working ambulating robots in the Sodarace domain,
which the original LLM had never seen in pre-training. <strong>These examples then help to bootstrap training a new conditional language model that can output the right walker for a particular terrain</strong>‚Äù</p>

<hr />

<p>My notes and highlights from the ELM paper by OpenAI, which uses a three-step invention pipeline combining LLM mutators, MAPElites (a genetic algorithm) and RL to design racing robots.</p>

<p>The three stages are:</p>
<ul>
  <li><strong>Data Generation through ELM</strong>: They use MAPElites to generate a grid of niches, then start with a seed (expressed in functioning Python code) and mutate it with a diff-based LLM repeatedly, until reaching very good candidates that fill multiple niches (defined with width, height and mass).</li>
  <li><strong>Language Model Training</strong>: After generating a big dataset of functioning Python code that codifies fit and diverse racers, a version of the diff-LLM is fit to generate more candidates, using a simple autoregressive loss. This way a language model is trained on a previously inexistent dataset for a specific kind of text.</li>
  <li><strong>Conditional RL</strong>: A RL model is trained that generates conditioned racers, initializing weights from the stage two LLM and conditioning it on a terrain embedding (which is fit using a ResNet over an image of the terrain) as input. This way, using run length as a reward, a new autoregressive model is trained, this time conditional, which generates even fitter, diverse racers (with some emerging properties)</li>
</ul>

<p>The authors discuss how this could be applied to other, open-ended tasks and spark innovation in multiple novel domains, and how innovation can bootstrap itself to develop more things (mentioning the concept of DCT).</p>

<hr />

<p><em>What follows is mostly excerpts and highlights.</em></p>

<p>This work aims to find synergy between Genetic Programming and LLMs.</p>

<p>‚ÄúIn this new Evolution through Large Models (ELM) approach, an <strong>LLM trained on code</strong> can suggest mutations that are intelligent, <strong>thereby facilitating a dramatically more effective mutation operator</strong> that sidesteps many of the challenges that previously existed for evolving programs‚Äù</p>

<p>‚ÄúThe set of
samples generated through the LLM can eventually constitute a new training
set in a novel domain that can then fine-tune the LLM to perform well in the
new domain, a novel data-generation procedure. Furthermore, this approach
ultimately opens up new opportunities in the pursuit of open-endedness by increasing the generative capabilities of the LLM solely through its own generated
data.‚Äù</p>

<p>Similar to self-supervised LLMs, we have a model that generates its own future training data. An Ouroboros of Artificial Intelligence. I love it.</p>

<p>‚ÄúWhile it might seem at first glance that
LLMs therefore might out-compete or subsume GP, in fact <strong>GP does still offer
an advantage</strong> in situations where the particular <strong>class of programs targeted by
the search is far (or even completely lacking) from the training distribution of
the LLM.</strong> In such cases, the LLM offers limited recourse (prompt engineering to
learn an entirely new domain would be prohibitive), while GP can in principle
evolve in any space (though in practice some spaces may be intractable due to
the amount of mutation necessary to get consistent signal on fitness).‚Äù</p>

<blockquote>
  <p>The LLM in concert with evolution can steer each other towards the right region of the solution space even
though neither evolution with a conventional mutation operator nor the LLM
on its own could generate anything close.</p>
</blockquote>

<p>‚Äúopen-endedness is fundamentally about <strong>searching
outside the distribution of previous experience</strong>, which is exactly what ELM
helps the LLM to do.‚Äù</p>

<p>Experiments that follow show that generated data is sufficiently rich that it can serve as training data for fine-tuning LLMs to generate
code for viable new Sodaracers consistently, and furthermore that reinforcement
learning (RL) can even fine-tune an augmented LLM to output Sodaracers conditionally, depending on the terrain.</p>

<p>One obstacle of making GP write code is that scaling GP to evolve increasingly complicated programs can be challenging, and that effectively applying GP to a new domain can require significant domain expertise. A researcher often must explicitly specify what functions, variables, and control structures are available to
evolution, which limits what ultimately can be evolved. In contrast,
a human programmer can open-endedly decide what libraries to import and
how to write many interdependent subroutines or classes.</p>

<p>A diff is an incremental change to a file that is committed to a version control system such as GitHub, accompanied by a commit
message describing the intent of the change. In this way, diff models are trained
how, given a piece of code and any potential commit message, to suggest an
informed change. Through the lens of evolutionary algorithms, such <strong>diff models can be viewed as intelligent perturbation operators</strong>, providing a way to walk
over the manifold of code (in a controllable way) through mimicking human programmers. An interesting further possibility is that <strong>such models are amenable
to further training through gradient descent, implying a potentially-powerful
mechanism for self-adaptation</strong> (e.g. through reinforcing successful diffs during
evolution). Both diff models and their capacity for self-adaptation are explored
in this work as a way to improve GP.</p>

<blockquote>
  <p>Within artificial life, the field of open-endedness seeks to create algorithmic systems that produce never-ending innovation.</p>
</blockquote>

<p>This paper argues that <strong>computer programs are a general and powerful encoding</strong> for continually expanding the richness of an existing environment.</p>

<h3 id="approach-evolution-through-large-models">Approach: Evolution through Large Models</h3>

<p>Three distinct components facilitate ELM.</p>
<ul>
  <li>The novel mutation operator driven by an LLM.</li>
  <li>An evolutionary outer loop that calls this mutation operator.</li>
  <li>A method for updating the LLM to improve based on its preceding performance.</li>
</ul>

<p><em>Diff models</em> are trained by giving an LLM the code file and a commit message (concatenated as input, files are small) and they need to predict the whole diff, but nothing else (this makes it impractical for it to just memorize the initial file).</p>

<p>To achieve meaningful mutations, ELM can choose among a set of commit
messages, which convey to the LLM the details of the operation it should perform in lieu of mutation.</p>

<p>The commit messages used are:</p>
<ul>
  <li>Changed make walker function.</li>
  <li>Changed parameters in make walker function.</li>
  <li>Small change to make walker function.</li>
</ul>

<p>‚ÄúWe do not yet know how to make an algorithm that exhibits
genuinely open-ended divergence. While there has been progress towards openendedness in recent years, the state of the art remains weak open-endedness,
wherein novel and interesting discovery continues only for a brief time, eventually ending in a plateau as the possibilities are exhausted.‚Äù</p>

<p>In contrast, in strong open-endedness, the process would never plateau‚Äìif we
left and returned a year later, or even a million years later, its products would
continue to become more interesting over time. No algorithm comes close to
such an achievement, though it is possible in nature.</p>

<blockquote>
  <p>The challenge of devising artificial environments with unbounded potential raises the intriguing question of what property our universe and planet possess that is lacking in current artificial environments.</p>
</blockquote>

<p>They discuss DCTs (Detached Conditional Things), things that don‚Äôt evolve organically but the agents can manipulate, create or move in multiple ways.</p>

<p>While any QD algorithm can work with ELM, the specific algorithm in the
experiment in this paper is MAP-Elites <a href="https://arxiv.org/abs/1504.04909">üå±</a>,<a href="https://doi.org/10.1145/3321707.3321799">üå±</a>.</p>

<p>The core of MAPElites is a uniformly-spaced grid of niches (called the map), that spans user-specified dimensions of solution diversity, called the behavior characterization.</p>

<p>Upon initialization, a single pre-existing (hand-designed in this paper) solution
is evaluated and placed into the map. In each iteration thereafter, an inhabited
niche is randomly chosen and the solution within that niche is perturbed by the
diff model and evaluated. The new candidate solution is assigned its niche from
its behavior characterization, and if that niche is unfilled or the new solution outperforms the niche‚Äôs current inhabitant, it becomes the champion of that niche;
otherwise, the candidate is discarded. In this way, over iterations of search, the
map gradually fills with increasingly diverse and high-quality solutions.</p>

<p>‚ÄúIn each iteration, an existing Python
solution is sampled from the map of solutions for each independent replica of
a diff model. Each replica generates a batch of diffs that are applied to the
sampled solution to generate modified candidate solutions. These candidates are
evaluated and are then inserted into the map if they either establish a new niche
or outperform the niche‚Äôs current champion.‚Äù</p>

<h3 id="fine-tuning-the-diff-operator">Fine-tuning the Diff Operator</h3>

<p>The pre-trained diff model can be trained further with
accepted diffs (by MAP-Elites) from initial iterations or runs of ELM.</p>

<p>Fine-tuning the diff model on accepted diffs from an initial series of runs
greatly increased performance; while Sodarace-generating programs
are out-of-distribution for the pretrained diff model (applying a Python encoding
to this domain is a novel enterprise), fine-tuning effectively aligns the diff model
with the domain, an interesting result.</p>

<p>The fine-tuned diff model produces a significantly higher percentage of diffs that are valid (i.e. able to be applied) and runnable (i.e. the patched program is executable).</p>

<p>Because of their higher performance, the output of runs applying the fine-tuned diff model are the ones passed to later stages in the pipeline.</p>

<h2 id="pipeline-stage-one-data-generation-through-elm">Pipeline Stage One: Data Generation through ELM</h2>

<p>‚ÄúELM shows that by combining an intelligent LLM-based mutation operator with a QD algorithm it is possible to generate <strong>hundreds of thousands of working training examples</strong> in a completely novel domain where no data was previously available.‚Äù</p>

<p>In this step, a 12x12x12 grid of height, width and mass is initialized with a seed program, and the mutation operator is repeatedly applied to individuals in the grid, which are then evlauated to see which niche (grid space) they fill and whether they beat that niche‚Äôs champion. If they do, they replace it.</p>

<p>The mutator LLM is optionally fine-tuned on diffs that generated valid outputs (physically viable, compiles and runs, etc.). This improves the model.</p>

<h2 id="pipeline-stage-two-language-model-training">Pipeline Stage Two: Language Model Training</h2>

<p>The second stage of the invention pipeline fine-tunes an LLM on the products of stage one.</p>

<p>From each run all solutions ever admitted to the map are
included, subject to meeting a minimal bar for performance. Some parts of
the behavior space offer more stringent challenges (e.g., tall, thin, no mass), and yet those kinds of solutions may yet be
most effective in some terrains, despite their low level of absolute performance. Thus, for each niche, the maximum performance across all runs is calculated, and the minimal bar for inclusion is set as a percentage of that per-niche score. With a higher percentage threshold, less data is included, but the quality of that data will be higher.</p>

<h2 id="pipeline-stage-three-conditional-rl">Pipeline Stage Three: Conditional RL</h2>

<p>They convert the model to a conditional one, i.e. a
model that accepts terrains as inputs, and produces samples of Sodaracers in
response.</p>

<p>Given a distribution over terrains <em>p(t)</em>, an RL setting is constructed to train
the parameters of the <em>TEN (Terrain Encoding Network)</em> and further finetune the LLM parameters to the conditional setting.</p>

<p>In particular, an episode now consists of sampling <em>t ‚àº p(t)</em>, and sampling a program from the conditional (autoregressive) distribution. The program is converted to a Sodaracer, evaluated in simulation with the terrain <em>t</em>, and the reward is defined as the absolute distance traversed by the Sodaracer in a given period of time.</p>

<p>The future vision is to lay the groundwork for the ability to
<strong>deploy agents capable of conditional invention in rich, potentially multi-agent
environments</strong> that support the development of open-ended processes.</p>

<p>A small set of terrains from which distributions that force conditionality can be constructed.</p>

<p>The embedding for the terrain (TEN) is <strong>constructed using ResNet-50, which is trained as part of the RL task</strong> (lots of parameters for small distribution, but may generalize better to new terrains).</p>

<p>Proximal policy optimization [PPO] is the RL algorithm, in conjunction with generalized advantage estimation [GAE], with default hyperparameters.</p>

<p>In short, the main result is the outputs of Stage 3, and thus the complete pipeline, are conditional inventors of the desired form.
Moreover, in most cases, the RL models are comparable to or better than the
best-performing Sodaracers sampled from the dataset or the pretrained LLM</p>

<h3 id="discussion">Discussion</h3>

<p>The problem then is that arbitrary mutations to an already-formulated program are
very unlikely to be useful.</p>

<p>A few years ago, the idea that the mutation operator could ‚Äúknow‚Äù how to
perturb such programs in reasonable and promising ways would be fanciful, but,
as shown in this paper, the emergence of LLMs has now made such capabilities
a reality.</p>

<h3 id="related-links">Related Links</h3>
<ul>
  <li><a href="https://news.ycombinator.com/item?id=32532875">Code completion with GPT-3</a>, a HackerNews thread with a nice example + template.</li>
</ul>

</div>
<a href='https://ko-fi.com/R6R3F4NIO' target='_blank' rel="noopener noreferrer nofollow">
  <img style='border:0px;height:4em;width:auto;' src='https://cdn.ko-fi.com/cdn/kofi5.png?v=3' border='0' alt='Buy Me a Coffee at ko-fi.com' loading='lazy'/></a>
  <p style='text-align: center;'>
  <a href="https://twitter.com/intent/tweet?text=Evolution through Large Models, OpenAI&url=https://strikingloo.github.io/wiki/evolution-through-large-models%2F%3Futm_source%3Dtwitter%26utm_medium%3Dsocial&via=strikingLoo" title="Share on Twitter!">[<svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 310 310" height="1em" width="1em" rel="noopener noreferrer nofollow"><path fill="#1DA1F2" d="M302.973 57.388a117.512 117.512 0 01-14.993 5.463 66.276 66.276 0 0013.494-23.73 5 5 0 00-7.313-5.824 117.994 117.994 0 01-34.878 13.783c-12.381-12.098-29.197-18.983-46.581-18.983-36.695 0-66.549 29.853-66.549 66.547 0 2.89.183 5.764.545 8.598C101.163 99.244 58.83 76.863 29.76 41.204a5.001 5.001 0 00-8.196.642c-5.896 10.117-9.013 21.688-9.013 33.461 0 16.035 5.725 31.249 15.838 43.137a56.37 56.37 0 01-8.907-3.977 5 5 0 00-7.427 4.257c-.007.295-.007.59-.007.889 0 23.935 12.882 45.484 32.577 57.229a57.372 57.372 0 01-5.063-.735 4.998 4.998 0 00-5.699 6.437c7.29 22.76 26.059 39.501 48.749 44.605-18.819 11.787-40.34 17.961-62.932 17.961a120.4 120.4 0 01-14.095-.826 5 5 0 00-3.286 9.174c29.023 18.609 62.582 28.445 97.047 28.445 67.754 0 110.139-31.95 133.764-58.753 29.46-33.421 46.356-77.658 46.356-121.367 0-1.826-.028-3.67-.084-5.508 11.623-8.757 21.63-19.355 29.773-31.536a5 5 0 00-6.182-7.351z"></path></svg>Share on twitter]</a></p>

<template id="post-delayed-content">

<div class="backButton">
<a href="https://twitter.com/intent/tweet?text=Evolution through Large Models, OpenAI&url=https://strikingloo.github.io/wiki/evolution-through-large-models%2F%3Futm_source%3Dtwitter%26utm_medium%3Dsocial&via=strikingLoo" id='tweetThis' title="Share on Twitter!" rel="noopener noreferrer nofollow">[<svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 310 310" height="1em" width="1em"><path fill="#1DA1F2" d="M302.973 57.388a117.512 117.512 0 01-14.993 5.463 66.276 66.276 0 0013.494-23.73 5 5 0 00-7.313-5.824 117.994 117.994 0 01-34.878 13.783c-12.381-12.098-29.197-18.983-46.581-18.983-36.695 0-66.549 29.853-66.549 66.547 0 2.89.183 5.764.545 8.598C101.163 99.244 58.83 76.863 29.76 41.204a5.001 5.001 0 00-8.196.642c-5.896 10.117-9.013 21.688-9.013 33.461 0 16.035 5.725 31.249 15.838 43.137a56.37 56.37 0 01-8.907-3.977 5 5 0 00-7.427 4.257c-.007.295-.007.59-.007.889 0 23.935 12.882 45.484 32.577 57.229a57.372 57.372 0 01-5.063-.735 4.998 4.998 0 00-5.699 6.437c7.29 22.76 26.059 39.501 48.749 44.605-18.819 11.787-40.34 17.961-62.932 17.961a120.4 120.4 0 01-14.095-.826 5 5 0 00-3.286 9.174c29.023 18.609 62.582 28.445 97.047 28.445 67.754 0 110.139-31.95 133.764-58.753 29.46-33.421 46.356-77.658 46.356-121.367 0-1.826-.028-3.67-.084-5.508 11.623-8.757 21.63-19.355 29.773-31.536a5 5 0 00-6.182-7.351z"></path></svg>]</a>
<br/>
<a href="/blog/" id='backToBlog' title="Back to blog" rel="noopener noreferrer">[‚Üê]</a>
</div>
</template>
<script>

const headings = document.querySelectorAll('h2[id],h3[id]');
for (var heading of headings) {
    heading.innerHTML = `<a href=#${heading.id}>${heading.innerHTML}</a>`;
}
function externalLinks() { for(var c = document.getElementsByTagName("a"), a = 0;a < c.length;a++) { var b = c[a]; b.getAttribute("href") && b.hostname !== location.hostname && (b.target = "_blank") } }
externalLinks();

function renderBottomButtons(){
  const templateNode = document.getElementById('post-delayed-content')
  const templateContentClone = templateNode.content.cloneNode(true) // perform a deep copy
  document.body.appendChild(templateContentClone)
}

function scrollEventHandler(){
 const scrollOffset = window.pageYOffset
 const browserViewHeight = window.innerHeight
 if (scrollOffset > browserViewHeight/3) {
    console.log('done')
    renderBottomButtons();
    window.removeEventListener('scroll', scrollEventHandler)
 }
}
window.addEventListener('scroll', scrollEventHandler)
</script>

<meta name="twitter:card" content="summary_large_image" />
<meta name="twitter:site" content="@StrikingLoo" />
<meta name="twitter:title" content="Evolution through Large Models, OpenAI" />
<meta name="twitter:description" content="Notes on the ELM paper, which uses a three-step invention pipeline combining LLM mutators, MAPElites (a genetic algorithm) and RL to design racing robots." />

<meta name="twitter:image:src" content="https://strikingloo.github.io/resources/book-tw.jpg"/>
<meta property="og:image" content="https://strikingloo.github.io/resources/preview-image-terrarium.png"/>

			
			</div>
			<footer>
	    		<ul>
	        		<li><a href="mailto:lucianostrika44@gmail.com" rel="me" title="email me">‚úâÔ∏è</a></li>
	        		<li><a href="https://github.com/strikingloo" rel="me noopener noreferrer nofollow" title="GitHub"><svg viewBox="0 0 438.549 438.549" xmlns="http://www.w3.org/2000/svg" height="1em" width="1em"><path fill="#0F3D3E" d="M409.132 114.573c-19.608-33.596-46.205-60.194-79.798-79.8-33.598-19.607-70.277-29.408-110.063-29.408-39.781 0-76.472 9.804-110.063 29.408-33.596 19.605-60.192 46.204-79.8 79.8C9.803 148.168 0 184.854 0 224.63c0 47.78 13.94 90.745 41.827 128.906 27.884 38.164 63.906 64.572 108.063 79.227 5.14.954 8.945.283 11.419-1.996 2.475-2.282 3.711-5.14 3.711-8.562 0-.571-.049-5.708-.144-15.417a2549.81 2549.81 0 01-.144-25.406l-6.567 1.136c-4.187.767-9.469 1.092-15.846 1-6.374-.089-12.991-.757-19.842-1.999-6.854-1.231-13.229-4.086-19.13-8.559-5.898-4.473-10.085-10.328-12.56-17.556l-2.855-6.57c-1.903-4.374-4.899-9.233-8.992-14.559-4.093-5.331-8.232-8.945-12.419-10.848l-1.999-1.431c-1.332-.951-2.568-2.098-3.711-3.429-1.142-1.331-1.997-2.663-2.568-3.997-.572-1.335-.098-2.43 1.427-3.289s4.281-1.276 8.28-1.276l5.708.853c3.807.763 8.516 3.042 14.133 6.851 5.614 3.806 10.229 8.754 13.846 14.842 4.38 7.806 9.657 13.754 15.846 17.847 6.184 4.093 12.419 6.136 18.699 6.136s11.704-.476 16.274-1.423c4.565-.952 8.848-2.383 12.847-4.285 1.713-12.758 6.377-22.559 13.988-29.41-10.848-1.14-20.601-2.857-29.264-5.14-8.658-2.286-17.605-5.996-26.835-11.14-9.235-5.137-16.896-11.516-22.985-19.126-6.09-7.614-11.088-17.61-14.987-29.979-3.901-12.374-5.852-26.648-5.852-42.826 0-23.035 7.52-42.637 22.557-58.817-7.044-17.318-6.379-36.732 1.997-58.24 5.52-1.715 13.706-.428 24.554 3.853 10.85 4.283 18.794 7.952 23.84 10.994 5.046 3.041 9.089 5.618 12.135 7.708 17.705-4.947 35.976-7.421 54.818-7.421s37.117 2.474 54.823 7.421l10.849-6.849c7.419-4.57 16.18-8.758 26.262-12.565 10.088-3.805 17.802-4.853 23.134-3.138 8.562 21.509 9.325 40.922 2.279 58.24 15.036 16.18 22.559 35.787 22.559 58.817 0 16.178-1.958 30.497-5.853 42.966-3.9 12.471-8.941 22.457-15.125 29.979-6.191 7.521-13.901 13.85-23.131 18.986-9.232 5.14-18.182 8.85-26.84 11.136-8.662 2.286-18.415 4.004-29.263 5.146 9.894 8.562 14.842 22.077 14.842 40.539v60.237c0 3.422 1.19 6.279 3.572 8.562 2.379 2.279 6.136 2.95 11.276 1.995 44.163-14.653 80.185-41.062 108.068-79.226 27.88-38.161 41.825-81.126 41.825-128.906-.01-39.771-9.818-76.454-29.414-110.049z"></path></svg></a></li>
			        <li><a href="https://twitter.com/intent/follow?screen_name=strikingloo" rel="me noopener noreferrer nofollow" title="twitter"><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 310 310" height="1em" width="1em"><path fill="#0F3D3E" d="M302.973 57.388a117.512 117.512 0 01-14.993 5.463 66.276 66.276 0 0013.494-23.73 5 5 0 00-7.313-5.824 117.994 117.994 0 01-34.878 13.783c-12.381-12.098-29.197-18.983-46.581-18.983-36.695 0-66.549 29.853-66.549 66.547 0 2.89.183 5.764.545 8.598C101.163 99.244 58.83 76.863 29.76 41.204a5.001 5.001 0 00-8.196.642c-5.896 10.117-9.013 21.688-9.013 33.461 0 16.035 5.725 31.249 15.838 43.137a56.37 56.37 0 01-8.907-3.977 5 5 0 00-7.427 4.257c-.007.295-.007.59-.007.889 0 23.935 12.882 45.484 32.577 57.229a57.372 57.372 0 01-5.063-.735 4.998 4.998 0 00-5.699 6.437c7.29 22.76 26.059 39.501 48.749 44.605-18.819 11.787-40.34 17.961-62.932 17.961a120.4 120.4 0 01-14.095-.826 5 5 0 00-3.286 9.174c29.023 18.609 62.582 28.445 97.047 28.445 67.754 0 110.139-31.95 133.764-58.753 29.46-33.421 46.356-77.658 46.356-121.367 0-1.826-.028-3.67-.084-5.508 11.623-8.757 21.63-19.355 29.773-31.536a5 5 0 00-6.182-7.351z"></path></svg></a></li>
			        <li><a href="http://www.linkedin.com/in/luciano-strika" rel="me noopener noreferrer nofollow" title="linkedin"><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 310 310" height="1em" width="1em"><path fill="#0F3D3E" d="M72.16 99.73H9.927a5 5 0 00-5 5v199.928a5 5 0 005 5H72.16a5 5 0 005-5V104.73a5 5 0 00-5-5zM41.066.341C18.422.341 0 18.743 0 41.362 0 63.991 18.422 82.4 41.066 82.4c22.626 0 41.033-18.41 41.033-41.038C82.1 18.743 63.692.341 41.066.341zM230.454 94.761c-24.995 0-43.472 10.745-54.679 22.954V104.73a5 5 0 00-5-5h-59.599a5 5 0 00-5 5v199.928a5 5 0 005 5h62.097a5 5 0 005-5V205.74c0-33.333 9.054-46.319 32.29-46.319 25.306 0 27.317 20.818 27.317 48.034v97.204a5 5 0 005 5H305a5 5 0 005-5V194.995c0-49.565-9.451-100.234-79.546-100.234z"></path></svg></a></li>
			        <li><a href="/resources/Luciano_Strika.pdf">CV</a></li>
				</ul>
				<p><i>Built with ‚ù§Ô∏è by <a href="https://strikingloo.github.io/">Strikingloo</a>.</i></p>
			</footer>
			

			

			
			<link rel="preload" href="/css/non-critical-post-min.css" as="style" onload="this.onload=null;this.rel='stylesheet'">
			<noscript><link rel="stylesheet" href="/css/non-critical-post-min.css"></noscript>
        	
		</body>
	</html>
